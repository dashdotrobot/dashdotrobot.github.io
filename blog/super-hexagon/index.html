<!doctype html>
<html lang="en">
<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-63010494-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-63010494-2');
  </script>

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">

  <!-- Page-specific stylesheets -->
  <link href="https://dashdotrobot.com/theme/css/style.css" rel="stylesheet">

  <!-- Fonts -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <link rel="stylesheet" href="https://dashdotrobot.com/theme/css/academicons.min.css"/>

  <title>dashdotrobot.com - How long will it take me to beat Super Hexagon?</title>
  <meta property="og:site_name" content="dashdotrobot.com" />
  <meta property="og:type" content="article"/>
  <meta property="og:title" content="How long will it take me to beat Super Hexagon?"/>
  <meta property="og:url" content="https://dashdotrobot.com/blog/super-hexagon/"/>
  <meta property="og:description" content="Will I ever beat Super Hexagon? I collect some data, calculate some statistics, construct a disjoint failure-rate model, and find out!"/>
  <meta property="article:published_time" content="2014-12-31" />
      <meta property="article:section" content="blog" />
      <meta property="article:tag" content="matlab" />
      <meta property="article:tag" content="diversions" />
      <meta property="article:author" content="Matt Ford" />
      <meta property="og:image"
            content="https://dashdotrobot.com/images/featured/super-hexagon.png"/>


    <meta name="tags" content="matlab" />
    <meta name="tags" content="diversions" />

</head>

<body id="index" class="home">

  <nav class="navbar navbar-expand-md sticky-top navbar-dark bg-accent">
    <div class="container">
    <a class="navbar-brand" href="https://dashdotrobot.com/">
<img class="d-inline-block align-top" src="https://dashdotrobot.com//images/site/avatar-light.png" width="30px"/>       dashdotrobot.com 
    </a>

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarNav">
      <ul class="navbar-nav mr-auto">

        <!-- Menu items -->

        <!-- Pages -->
        <li class="nav-item"><a class="nav-link" href="https://dashdotrobot.com/curriculum-vitae/">C.V.</a></li>
        <li class="nav-item"><a class="nav-link" href="https://dashdotrobot.com/projects/">Projects</a></li>
        <li class="nav-item"><a class="nav-link" href="https://dashdotrobot.com/teaching/">Teaching</a></li>

        <!-- Article categories -->
        <li class="nav-item active">
          <a class="nav-link" href="https://dashdotrobot.com/blog/">Blog</a>
        </li>
      </ul>

      <ul class="navbar-nav ml-auto">
        <li class="nav-item mx-1"><a class="nav-link" href="http://twitter.com/dashdotrobot" target="_blank"><i class="fab fa-twitter-square fa-lg icon"></i> <span class="d-md-none">Twitter</span></a></li>
        <li class="nav-item mx-1"><a class="nav-link" href="https://github.com/dashdotrobot" target="_blank"><i class="fab fa-github-square fa-lg icon"></i> <span class="d-md-none">GitHub</span></a></li>
        <li class="nav-item mx-1"><a class="nav-link" href="https://scholar.google.com/citations?user=Gho4h7kAAAAJ&hl=en" target="_blank"><i class="ai ai-google-scholar-square ai-lg icon"></i> <span class="d-md-none">Google Scholar</span></a></li>
        <li class="nav-item mx-1"><a class="nav-link" href="https://www.linkedin.com/in/matthew-ford-phd" target="_blank"><i class="fab fa-linkedin fa-lg icon"></i> <span class="d-md-none">LinkedIn</span></a></li>
      </ul>

    </div>
    </div>
  </nav>


<div class="container main-content">
  <div class="row">
    <div class="col-md-9">

<section id="content" class="body">
  <header>
    <h2 class="entry-title">
      <a href="https://dashdotrobot.com/blog/super-hexagon/" rel="bookmark"
         title="Permalink to How long will it take me to beat Super Hexagon?">How long will it take me to beat Super Hexagon?</a></h2>
 
  </header>
  <footer class="post-info">
    <small><time class="published" datetime="2014-12-31T00:00:00-06:00">
      Wednesday, December 31, 2014
    </time></small>
    <address class="vcard author">
      <small>By           <a class="url fn" href="https://dashdotrobot.com/author/matt-ford.html">Matt Ford</a>
</small>
    </address>
    <!-- <div class="category"> -->
        <!-- Category: <a href="https://dashdotrobot.com/blog/">blog</a> -->
    <!-- </div> -->
    <div class="tags">
        Tags:
            <a href="https://dashdotrobot.com/tag/matlab.html">matlab</a>
            <a href="https://dashdotrobot.com/tag/diversions.html">diversions</a>
    </div>
  </footer><!-- /.post-info -->
  <div class="entry-content">
    <p>Terry Cavanagh's Super Hexagon is the hardest game I've ever played. The gameplay is addictive, to say the least. The feeling is akin to what I imagine slot machine play must feel like to a gambling addict. Except these are the penny-slots. A single game can cost less than 5 seconds before you crash into one of the infinite, endlessly collapsing geometric shapes. There is no natural end, just a series of checkpoints, the last of which ("Hexagon") comes at 60 seconds. So given that a typical game for me lasts about 8 seconds, how many times do I have to play until I surmount the final barrier?</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/5mDjFdetU28" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="gathering-statistics">Gathering statistics</h2>
<p>The goal of Super Hexagon is to dodge an endless stream of collapsing line segments and survive as long as possible. First I generated some data on my gameplay. I played 150 consecutive games on "hexagonest" mode and recorded my score (survival time) for each. I have already been playing this game off and on for about a month, so there's reason to believe that my learning curve is relatively flat. Additionally, I played a few warm-up matches before recording statistics.</p>
<p>One of my central assumptions will be that my performance from match to match is <a href="http://en.wikipedia.org/wiki/Stationary_process">stationary</a>, that is, my score on match <span class="math">\(n\)</span> is independent of my score on previous matches and does not depend on how many matches I have played.</p>
<p><img alt="Average performance over time" src="https://dashdotrobot.com/images/super-hexagon/time_bins1.png" /></p>
<p>If I was getting better over time, I would expect my median performance to shift upwards. The plot above shows the outcomes of all the matches in light gray and the medians (and 20% and 80% percentiles) for each group of 15 matches. I don't seem to be improving (or getting worse) over time. Secondly my performance on match <span class="math">\(n\)</span> is uncorrelated with my performance on match <span class="math">\(n-1\)</span> (corresponding to a lag of 1 in the autocorrelation function shown below). The outcome of the <a href="http://en.wikipedia.org/wiki/Ljung%E2%80%93Box_test">Ljung-Box</a> test also comes up negative for a lag of 1, confirming what we can already tell visually. Namely, that doing well (or poorly) on a match doesn't cause me to do any better (or worse) on the next match.</p>
<p><img alt="Time-lag autocorrelation" src="https://dashdotrobot.com/images/super-hexagon/autocorr1.png" /></p>
<h2 id="extreme-distributions">Extreme distributions</h2>
<p>So if my match-to-match performance is a stationary process, what is the distribution of survival times? As expected, I typically <a href="http://www.slate.com/articles/arts/culturebox/2014/01/samuel_beckett_s_quote_fail_better_becomes_the_mantra_of_silicon_valley.html">fail early and often</a>. The game presents a variety of different challenges, but they are randomly generated each time, so there's reason to believe that my failure statistics might follow an <a href="http://en.wikipedia.org/wiki/Exponential_distribution">exponential distribution</a>. Why is that? Well, let's assume that in each instant, my failure probability is constant (because the game presents the same challenge, on average, at every moment). Therefore my tendency to make a mistake is a <a href="http://en.wikipedia.org/wiki/Poisson_process">Poisson process</a>.</p>
<p><img alt="Histogram of survival times" src="https://dashdotrobot.com/images/super-hexagon/hist.png" /></p>
<p>The cumulative distribution function <span class="math">\(F(t)\)</span> gives the probability that the failure time will be less than <span class="math">\(t\)</span>. So the probability of exceeding a certain threshold is <span class="math">\(1−F(t)\)</span>. The exponential distribution, <span class="math">\(F(t)=1−e^{−λt}\)</span> yields a very poor fit to the data. The two-parameter Weibull distribution function, <span class="math">\(F(t)=1−e^{(t/τ)^k}\)</span> does much better. We'll look at the key difference between these distributions later.</p>
<p><img alt="Cumulative probability of survival times" src="https://dashdotrobot.com/images/super-hexagon/cdf.png" /></p>
<h2 id="waiting-for-a-black-swan">Waiting for a Black Swan</h2>
<p>How do we predict the probability of occurrence of an event that we've never witnessed? Nassim Nicholas Taleb refers to this kind of event as a <a href="http://en.wikipedia.org/wiki/Black_swan_theory">Black Swan</a>, especially if it has a disproportionate impact, like a market crash or extreme flood.</p>
<blockquote>
<p>First, [A Black Swan] is an outlier, as it lies outside the realm of regular expectations, because nothing in the past can convincingly point to its possibility. Second, it carries an extreme 'impact'. Third, in spite of its outlier status, human nature makes us concoct explanations for its occurrence after the fact, making it explainable and predictable.</p>
<p><em>Nassim Nicholas Taleb, The Black Swan</em></p>
</blockquote>
<p>But how hard could it be to predict? If we trust that we have modeled the underlying distribution properly, why not just extrapolate out to 60 seconds and calculate the probability of success? Let's call the probability that the survival time exceeds 60 seconds <span class="math">\(P_{60}\)</span>. The probability that I will succeed after <span class="math">\(n\)</span> tries is</p>
<div class="math">$$P(\textrm{succeed after n}) = 1 − P(\textrm{fail after n})=1−(1−P_{60})^n$$</div>
<p>The number of attempts I will need to make in order to be 95% certain of success is <span class="math">\(\frac{\ln{(1-0.95)}}{\ln{(1-P_{60})}}\)</span>. Extrapolating the two-parameter Weibull distribution to find <span class="math">\(P_{60}\)</span> and assuming that each game takes 9.6 seconds each leads a prediction of 2 billion years. I could do better things with that time, like maybe finish my PhD.</p>
<h2 id="the-trouble-with-tails">The trouble with tails</h2>
<p>The problem with predicting extreme events by extrapolating mundane data is that the prediction is extremely sensitive to the shape of the <strong>tail</strong> of the distribution (the shape at large values). There is some statistical uncertainty in the fitting parameters, in this case, for <span class="math">\(\lambda\)</span> and <span class="math">\(k\)</span> for the Weibull distribution. Depending on the confidence level you select (95% for many applications), each parameter is expressed as <span class="math">\(p\pm \epsilon\)</span>. By taking the largest and smallest values for <span class="math">\(\lambda\)</span> and <span class="math">\(k\)</span>, we get two new distributions from which we can calculate two new time estimates.</p>
<p><img alt="Weibull upper and lower bounds" src="https://dashdotrobot.com/images/super-hexagon/weib_bounds.png" /></p>
<p>The confidence bounds are shown with dotted red lines. The tails of all three distributions are indistinguishable, but they give very different estimates. The lower estimate predicts 21 million years, while the upper one predicts 260 billion years or <strong>20 times the age of the universe!</strong> Mind you, these estimates come from the statistical uncertainty of the fit and do not represent upper and lower bounds, in any sense, of the actual time required. So clearly, the prediction of extreme events is extremely sensitive to the shape of the tail. So what governs the shape?</p>
<h2 id="beginners-luck-vs-flow">Beginner's Luck vs. "Flow"</h2>
<p>The Weibull distribution (and the exponential distribution, which is just a special case where <span class="math">\(k=1\)</span>) is often used to model the time-to-failure of parts or materials, or the time between discrete events like earthquakes or floods. If the distribution of times-to-failure is known, the instantaneous failure risk (the probability of failure occurring in the time interval <span class="math">\(t\)</span> to <span class="math">\(t+dt\)</span> can be calculated. If <span class="math">\(P(t)\)</span> is the cumulative distribution function of failure times, the failure risk is</p>
<div class="math">$$r(t)=\frac{\frac{dF}{dt}}{1−F(t)}$$</div>
<p>So, for the Weibull distribution (<span class="math">\(F(t)=1-e^{-(t/\lambda)^k}\)</span>), the failure risk is</p>
<div class="math">$$r(t)= \frac{k(\frac{t}{λ})^{k−1} \frac{1}{λ}e^{−(t/λ)^k}} {e^{−(t/λ)^k}} = \frac{k}{\lambda} \left(\frac{t}{\lambda}\right)^{k-1}$$</div>
<p>So the failure risk follows a power law with time. For the special case of an exponential distribution (<span class="math">\(k=1\)</span>), the risk is constant with time.</p>
<p><img alt="Failure risk vs. time" src="https://dashdotrobot.com/images/super-hexagon/f_risk1.png" /></p>
<p>Why might the failure risk change over time? Super Hexagon requires concentration (also the ability to not blink...) so your tendency to make a mistake may increase as you lose mental focus. After some time though, I've found that I lose my sense of time somewhat and experience what some call "flow." Additionally, the pace of the game increases at the beginning and then stabilizes, until speeding up again after 60 seconds. So I might expect that my failure risk increases at first (which is consistent with the curvature of the cumulative probability distribution near zero) and then levels off eventually. <strong>The behavior of <span class="math">\(r(t)\)</span> determines the shape of <span class="math">\(F(t)\)</span> and therefore the shape of the tail.</strong></p>
<p>There's no reason to assume that the failure risk <span class="math">\(r(t)\)</span> follows a power law for all times. In fact, we can derive the time-to-failure probability distribution given an arbitrary (integrable) risk function. We want to calculate <span class="math">\(F(t)\)</span>, the probability that failure has occurred before time <span class="math">\(t\)</span>. Of course this is just <span class="math">\(1−G(t)\)</span>, where <span class="math">\(G(t)\)</span> is the probability that failure has not occurred. This must be equal to the probability of failure not occurring in the interval from <span class="math">\(0\)</span> to <span class="math">\(\Delta t\)</span>, AND the probability of failure not occurring in the interval <span class="math">\(\Delta t\)</span> to <span class="math">\(2\Delta t\)</span>, etc. The failure probability in each interval is assumed to be independent, just like coin flips, so we can just multiply the probabilities of no failure in each interval. Dividing up the interval <span class="math">\((0,t)\)</span> into equal intervals of size <span class="math">\(\Delta t\)</span> and evaluating <span class="math">\(r(t)\)</span> at the center of each interval, we have</p>
<div class="math">$$1-F(t) = (1-r(\Delta t/2)\Delta t) \cdot (1-r(\Delta t+\Delta t/2)\Delta t) \cdot ...$$</div>
<p>Taking the natural log of both sides, the product on the right-hand-side becomes a sum.</p>
<div class="math">$$\ln{(1-F(t))} = \sum_{k=0}^{t/\Delta t} \ln{\left( 1-r\left(\frac{2k+1}{2}\Delta t\right)\right)}$$</div>
<p>If we let <span class="math">\(\Delta t\)</span> shrink to zero, the sum becomes an integral, and the argument <span class="math">\(\ln{(1-r(t))}\)</span> is approximated by its first order Taylor expansion, <span class="math">\(\ln{(1-r(\Delta t))}\approx-r(\Delta t)\)</span>. Therefore,</p>
<div class="math">$$\ln{(1-F(t))} = -\int_0^t r(t) dt$$</div>
<p>Now we can evaluate <span class="math">\(F(t)\)</span> for an arbitrary risk function. I'll assume that my failure risk becomes constant after 10 seconds. The cumulative probability distribution for this model is <span class="math">\(F(t)=1−e^{I_0−(t−t_c)/\mu}\)</span>, where <span class="math">\(I_0\)</span> is the value of the integral up to the cutoff point <span class="math">\(t_c=10\)</span> seconds. The fit looks like this:</p>
<p><img alt="Piecewise model for cumulative distribution" src="https://dashdotrobot.com/images/super-hexagon/cdf_partial.png" /></p>
<p>This model also leaves out the uncertainty in the first 10 seconds of the game, which has its own statistical problems but isn't relevant to predicting long times. The new model predicts that I will have to play the game for <strong>150 days</strong>. That assumes constant gameplay without eating or sleeping. That might sound daunting, but it's a far cry from 260 billion years!</p>
<p>Why does this matter? First, it's fun! Second, this dataset is an excellent example of how prediction of extreme events is very sensitive to how we model the <strong>tail</strong> of the probability distribution. We have to do more than selecting a model and then optimizing the goodness-of-fit. For best results, we should model the tail of the distribution with a equation which is based on the underlying phenomena we are trying to predict.</p>
<p>Of course, in the time it took me to write this, I bet I could have gotten better at this stupid game...</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
  </div><!-- /.entry-content -->
</section>

</div>

    <div class="col-md-3" id="sidebar">
      <div class="d-md-none py-3"><h3 class="text-center text-secondary">...</h3></div>
      <div class="card border-left">
        <img class="img-fluid" src="/images/site/Matt_Ford_small.png">
        <div class="card-body p-2">
          <p class="m-0"><small>My name is <strong>Matt Ford</strong>. I'm currently a postdoc working on active learning in
			 mechanical engineering at Cornell University. I received my Ph.D. from Northwestern University
             in Mechanical Engineering for my work on the mechanics of the bicycle wheel.</small></p>
        </div>
      </div>
    </div>

<footer>
<div class="container-fluid text-center py-3">
  <small>&copy; 2020 <a href="http://dashdotrobot.com" target="_blank">Matthew Ford</a>.
    Powered by <a href="https://getpelican.com" target="_blank">Pelican</a> and <a href="https://getbootstrap.com/" target="_blank">Bootstrap</a>.
  </small>
</div>
</footer>

<!-- Bootstrap -->
<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx" crossorigin="anonymous"></script>



</body>
</html>